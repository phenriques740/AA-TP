{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho Prático Aprendizagem Automática\n",
    "\n",
    "## Introdução\n",
    "\n",
    "### Outras Cenas tenho preguiça de escrever, nomeadamente introdução teórica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer\n",
    "#Possiveis de serem usadas : numpy, scipy, matplotlib, sklearn, nltk, re e opencv \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imdbCriticas.p', 'rb') as f:\n",
    "    global D, Docs, y\n",
    "    D = pickle.load(f)\n",
    "    Docs = D.data\n",
    "    y = D.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos este metodo para préprocessar os dados de texto, e reduzir as palavras tendo em conta os erros de ortografia\n",
    "\n",
    "O stemmer por defeito é o porter e se o argumento não corresponder a nenhum outro, este é utilizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessDoc(Doc, stemmer = 'porter', decode = False):\n",
    "    stem = {\n",
    "        'porter'   : PorterStemmer(),\n",
    "        'snowball' : SnowballStemmer('english'),\n",
    "        'lancaster': LancasterStemmer()\n",
    "    }\n",
    "    stemFunc = stem.get(stemmer, PorterStemmer())\n",
    "    if(decode):\n",
    "        Doc = Doc.decode('UTF-8')\n",
    "    Doc = Doc.replace('<br />', ' ')\n",
    "    Doc = re.sub(r'[^a-zA-Z\\u00C0\\u00FF]+', ' ', Doc)\n",
    "    return Doc\n",
    "\n",
    "def preProcessDocs(Docs, stemmer='porter', decode = False):\n",
    "    return [preProcessDoc(doc, stemmer, decode) for doc in Docs]\n",
    "\n",
    "def text2vector(Docs):\n",
    "    X = tfidf.transform(Docs)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  1 10  1  2  8  8  1 10  2]\n",
      "[1, 0, 1, 0, 0, 1, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# [f(x) if condition else g(x) for x in sequence]\n",
    "y_boolean = [0 if val<4 else 1 for val in y]\n",
    "\n",
    "print(y[:10])\n",
    "print(y_boolean[:10])\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(Docs,y_boolean,test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparar classificacao com stopwords e sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token len 35775\n",
      "Train score 0.936833\n",
      "Test score  0.8479\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=3, token_pattern=r'\\b\\w\\w\\w+\\b', stop_words='english').fit(x_train)\n",
    "tokens = tfidf.get_feature_names()\n",
    "print('Token len' , len(tokens))\n",
    "\n",
    "X1 = text2vector(x_train)\n",
    "X2 = text2vector(x_test)\n",
    "\n",
    "dl = LogisticRegression(max_iter = 1000, C=3.3, tol = 1e-3)\n",
    "dl.fit(X1,y_train)\n",
    "\n",
    "print('Train score' , round(dl.score(X1,y_train),6))\n",
    "print('Test score ' , round(dl.score(X2,y_test), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token len 36052\n",
      "Train score 0.931067\n",
      "Test score  0.8502\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=3, token_pattern=r'\\b\\w\\w\\w+\\b').fit(x_train)\n",
    "tokens = tfidf.get_feature_names()\n",
    "print('Token len' , len(tokens))\n",
    "\n",
    "X1 = text2vector(x_train)\n",
    "X2 = text2vector(x_test)\n",
    "\n",
    "dl = LogisticRegression(max_iter = 1000, C=3.3, tol = 1e-3)\n",
    "dl.fit(X1,y_train)\n",
    "\n",
    "print('Train score' , round(dl.score(X1,y_train),6))\n",
    "print('Test score ' , round(dl.score(X2,y_test), 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a preservação das stopwords, o classificador obtem melhores resultados, esta diferença será mais visivel com a presença de N-gramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparacao com variacao da min_df\n",
    "\n",
    "A min_df corresponde ao numero de repeticoes que tem de existir entre os documentos para que a palavra seja adicionada como token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ESTA MAL CORRIGE ISTO** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------- \n",
      "C 1\n",
      "train 0.895133\n",
      "test 0.8477\n",
      "diff 0.047433\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "C 2\n",
      "train 0.914567\n",
      "test 0.851\n",
      "diff 0.063567\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "C 3\n",
      "train 0.927667\n",
      "test 0.8507\n",
      "diff 0.076967\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "C 4\n",
      "train 0.937833\n",
      "test 0.8499\n",
      "diff 0.087933\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "C 5\n",
      "train 0.9456\n",
      "test 0.8499\n",
      "diff 0.0957\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "C 6\n",
      "train 0.9513\n",
      "test 0.8481\n",
      "diff 0.1032\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "C 7\n",
      "train 0.956033\n",
      "test 0.8455\n",
      "diff 0.110533\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "C 8\n",
      "train 0.9601\n",
      "test 0.8451\n",
      "diff 0.115\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "C 9\n",
      "train 0.963567\n",
      "test 0.8437\n",
      "diff 0.119867\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "vals = np.arange(1, 10 , 1)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for c in vals:\n",
    "    tfidf = TfidfVectorizer(min_df=c, token_pattern=r'\\b\\w\\w\\w+\\b').fit(x_train)\n",
    "\n",
    "    dl = LogisticRegression(max_iter = 1000, C=3,3, tol = 1e-3)\n",
    "    dl.fit(X1,y_train)## Classificacao booleana, uni-gramas\n",
    "    print('-'*100, '\\nC', round(c,2))\n",
    "    train_score =round(dl.score(X1,y_train),6)\n",
    "    train_scores.append(train_score)\n",
    "    print('train' ,train_score)\n",
    "    test_score = round(dl.score(X2,y_test),6)\n",
    "    test_scores.append(test_score)\n",
    "    print('test' ,test_score)\n",
    "    print('diff' , round(train_score-test_score,6))\n",
    "    print('-'*100)\n",
    "\n",
    "diff = np.array(train_scores) - np.array(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao aumentar o min_df vemos que o classificador entra rapidamente em sobre aprendizagem. O melhor resultado corresponde a um **valor de 3.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificacao booleana, uni-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=3, token_pattern=r'\\b\\w\\w\\w+\\b').fit(x_train)\n",
    "tokens = tfidf.get_feature_names()\n",
    "print(tokens[50:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = text2vector(x_train)\n",
    "X2 = text2vector(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X1))\n",
    "print(X1.shape, X2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.arange(0.1, 5 , 0.2)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for c in vals:\n",
    "    dl = LogisticRegression(max_iter = 1000, C=c, tol = 1e-3)\n",
    "    dl.fit(X1,y_train)## Classificacao booleana, uni-gramas\n",
    "    print('-'*100, '\\nC', round(c,2))\n",
    "    train_score =round(dl.score(X1,y_train),6)\n",
    "    train_scores.append(train_score)\n",
    "    print('train' ,train_score)\n",
    "    test_score = round(dl.score(X2,y_test),6)\n",
    "    test_scores.append(test_score)\n",
    "    print('test' ,test_score)\n",
    "    print('diff' , round(train_score-test_score,6))\n",
    "    print('-'*100)\n",
    "\n",
    "diff = np.array(train_scores) - np.array(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com um C mais pequeno, a diferença entre o train e test é menor mas os resultados são piores.\n",
    "\n",
    "O C que obteve os melhores resultados com menos erros foi o 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificacao booleana, N-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=3, token_pattern=r'\\b\\w\\w\\w+\\b', ngram_range=(1,3)).fit(x_train)\n",
    "tokens = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliografia\n",
    "- Slides Professor\n",
    "- https://blog.ekbana.com/pre-processing-text-in-python-ad13ea544dae\n",
    "- https://medium.com/@wenxuan0923/feature-extraction-from-text-using-countvectorizer-tfidfvectorizer-9f74f38f86cc\n",
    "- https://scikit-learn.org/stable/modules/grid_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
