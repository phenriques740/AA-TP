{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "structured-archive",
   "metadata": {},
   "source": [
    "# Trabalho Prático Aprendizagem Automática\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, pickle, time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "from sklearn.model_selection import cross_val_score , GridSearchCV , RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer\n",
    "#Possiveis de serem usadas : numpy, scipy, matplotlib, sklearn, nltk, re e opencv "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-helping",
   "metadata": {},
   "source": [
    "Carregar os ficheiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imdbCriticas.p', 'rb') as f:\n",
    "    global D, Docs, y\n",
    "    D = pickle.load(f)\n",
    "    Docs = D.data\n",
    "    y = D.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-duplicate",
   "metadata": {},
   "source": [
    "Usamos este metodo para préprocessar os dados de texto, e reduzir as palavras tendo em conta os erros de ortografia\n",
    "\n",
    "O stemmer por defeito é o lancaster, porque teve os melhores resultados e se o argumento não corresponder a nenhum outro, este é utilizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessDoc(Doc, stemmer = 'lancaster', decode = False):\n",
    "    stem = {\n",
    "        'porter'   : PorterStemmer(),\n",
    "        'snowball' : SnowballStemmer('english'),\n",
    "        'lancaster': LancasterStemmer()\n",
    "    }\n",
    "    stemFunc = stem.get(stemmer, LancasterStemmer())\n",
    "    if(decode):\n",
    "        Doc = Doc.decode('UTF-8')\n",
    "    Doc = Doc.replace('<br />', ' ')\n",
    "    Doc = re.sub(r'[^a-zA-Z\\u00C0\\u00FF]+', ' ', Doc)\n",
    "    Doc = ' '.join([stemFunc.stem(w) for w in Doc.split()])\n",
    "    return Doc\n",
    "\n",
    "def preProcessDocs(Docs, stemmer='lancaster', decode = False):\n",
    "    return [preProcessDoc(doc, stemmer, decode) for doc in Docs]\n",
    "\n",
    "def text2vector(Docs, preProcess = False, stemmer='lancaster', decode=False):\n",
    "    if(preProcess):\n",
    "        Docs = preProcessDocs(Docs, stemmer=stemmer, decode=decode)\n",
    "    \n",
    "    global tfidf\n",
    "    if(tfidf is None):\n",
    "        tfidf = TfidfVectorizer(min_df=3, token_pattern=r'\\b\\w{3,}\\b', ngram_range=(1,2), norm = 'l2').fit(preProcessDocs(Docs))\n",
    "    X = tfidf.transform(Docs)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-geography",
   "metadata": {},
   "source": [
    "## Classificação Binária\n",
    "\n",
    "Converter da escala de 0 a 10, para negativos/positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_boolean = [0 if val<5 else 1 for val in y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-island",
   "metadata": {},
   "source": [
    "### Steemers\n",
    "\n",
    "O stemmer reduz uma palavra á sua raiz, ou seja, remove plurais, conjugacao de verbos, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-confidence",
   "metadata": {},
   "source": [
    "#### Porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preProcessDocs(Docs, stemmer='porter')\n",
    "tfidf = TfidfVectorizer(min_df=3, token_pattern=r'\\b[a-zA-Z]{3,}\\b').fit(X)\n",
    "vector = text2vector(X)\n",
    "dl = LogisticRegression(max_iter = 1000, C=3.3, tol = 1e-3).fit(vector,y_boolean)\n",
    "print('Token len' , len(tfidf.get_feature_names()))\n",
    "print(dl.score(vector, y_boolean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-intent",
   "metadata": {},
   "source": [
    "#### Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preProcessDocs(Docs, stemmer='snowball')\n",
    "tfidf = TfidfVectorizer(min_df=3, token_pattern=r'\\b[a-zA-Z]{3,}\\b').fit(X)\n",
    "vector = text2vector(X)\n",
    "dl = LogisticRegression(max_iter = 1000, C=3.3, tol = 1e-3).fit(vector,y_boolean)\n",
    "print('Token len' , len(tfidf.get_feature_names()))\n",
    "print(dl.score(vector, y_boolean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-cleaning",
   "metadata": {},
   "source": [
    "#### Lancaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-fifteen",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = preProcessDocs(Docs, stemmer='lancaster')\n",
    "tfidf = TfidfVectorizer(min_df=3, token_pattern=r'\\b[a-zA-Z]{3,}\\b').fit(X)\n",
    "vector = text2vector(X)\n",
    "dl = LogisticRegression(max_iter = 1000, C=3.3, tol = 1e-3).fit(vector,y_boolean)\n",
    "print('Token len' , len(tfidf.get_feature_names()))\n",
    "print(dl.score(vector, y_boolean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-creator",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('P' ,26773/0.945525)\n",
    "print('S' ,26394/0.94535)\n",
    "print('L' ,21883/0.939425)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-account",
   "metadata": {},
   "source": [
    "É possivel ver que o lancaster é o que reduz ao maximo a quantidade de tokens, alem disso vamos optar por utilizar o Lancaster pois precisava de uma quantidade de tokens menores para atingir os teoricos 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-effectiveness",
   "metadata": {},
   "source": [
    "## Comparar modelos lineares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline =Pipeline([\n",
    "    ('tfidf' , TfidfVectorizer(token_pattern=r'\\b\\w{3,}\\b', norm = 'l2')),\n",
    "    ('clf' , LogisticRegression(max_iter = 1000, solver='saga', tol=1e-5))\n",
    "])\n",
    "\n",
    "grid_param ={\n",
    "    #'tfidf__strip_accents' :[None, 'unicode'],\n",
    "    #'tfidf__stop_words' : [None, 'english'],\n",
    "    #'tfidf__token_pattern' : [r'\\b\\w{3,}\\b', r'\\b[a-zA-Z]{3,}\\b'],\n",
    "    'tfidf__min_df' : np.arange(1, 5, 1),\n",
    "    #'tfidf__min_df' : [3,4,5],\n",
    "    #'tfidf__min_df' : [3],\n",
    "    #'tfidf__ngram_range' : [(i,j) for i in range(1,5) for j in range(1,5)],\n",
    "    'tfidf__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "    #'tfidf__norm' : ['l1', 'l2'],\n",
    "    \n",
    "    #'clf__C' : np.linspace(0.1,10,100),\n",
    "    'clf__C' :[0.1, 3.3,5.0,10,100], \n",
    "    #'clf__C' : [3.3],\n",
    "    #'clf__solver' : ['sag', 'saga'],\n",
    "    #'clf__tol' : (1e-3, 1e-4, 1e-5)\n",
    "}\n",
    "print('brace yourselfs')\n",
    "grid_search = RandomizedSearchCV(pipeline, grid_param, scoring='accuracy', cv = 5, n_jobs=-1, verbose=2,n_iter = 5).fit(X, y_boolean)\n",
    "print('done')\n",
    "with open('dump.p', 'wb') as f:\n",
    "    pickle.dump({'in' : grid_param , 'out' :grid_search}, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-induction",
   "metadata": {},
   "source": [
    "## Em vez de correr o codigo em cima, podemos fazer import do ficheiro dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dump.p' ,'rb') as f:\n",
    "    global grid_param, grid_search\n",
    "    temp = pickle.load(f)\n",
    "    grid_param = temp['param']\n",
    "    grid_search = temp['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-interim",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-alaska",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-presence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-graham",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-evans",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-internet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-arcade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-adapter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-laundry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-demonstration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-seller",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-invalid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-newman",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-tower",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-legislation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-cause",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-heater",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sought-blade",
   "metadata": {},
   "source": [
    "# Bibliografia\n",
    "\n",
    "### Geral\n",
    "- Slides Professor\n",
    "\n",
    "### Pré processamento do texto\n",
    "- https://blog.ekbana.com/pre-processing-text-in-python-ad13ea544dae\n",
    "- https://medium.com/@wenxuan0923/feature-extraction-from-text-using-countvectorizer-tfidfvectorizer-9f74f38f86cc\n",
    "\n",
    "### Escolher o classificador\n",
    "- https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "\n",
    "### Grid Search\n",
    "- https://scikit-learn.org/stable/modules/grid_search.html\n",
    "- https://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html\n",
    "- https://www.youtube.com/watch?v=Gol_qOgRqfA\n",
    "\n",
    "### Pipeline\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline\n",
    "\n",
    "### Clustering\n",
    "- https://medium.com/hanman/data-clustering-what-type-of-movies-are-in-the-imdb-top-250-7ef59372a93b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-ballet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
